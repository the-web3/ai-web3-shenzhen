# =============================================================================
# Web3 RAG 环境变量配置示例
# =============================================================================
# 复制此文件为 .env 并根据实际情况修改
# cp .env.example .env

# =============================================================================
# LLM API 配置 (LlamaFactory)
# =============================================================================
# LlamaFactory API 服务地址
LLM_API_BASE=http://localhost:8000/v1

# 模型名称 (需与 LlamaFactory 配置一致)
LLM_MODEL=qwen3-4b

# 上下文窗口大小
LLM_CONTEXT_WINDOW=12000

# 最大生成 token 数
LLM_MAX_TOKENS=4096

# 采样温度 (0.0-1.0, 越低越确定)
LLM_TEMPERATURE=0.4

# =============================================================================
# Embedding 模型配置
# =============================================================================
# Embedding 模型路径 (本地路径或 HuggingFace 模型名)
EMBEDDING_MODEL=./models/qwen3-embedding-4b

# Embedding 运行设备 (cuda / cpu)
# 当 GPU 显存不足时，可设为 cpu
EMBEDDING_DEVICE=cuda

# Embedding 批处理大小
EMBEDDING_BATCH=2

# =============================================================================
# RAG 配置
# =============================================================================
# 知识库目录
RAG_KNOWLEDGE_BASE=./data/knowledge_base

# 向量索引存储目录
RAG_INDEX_STORAGE=./data/index_storage

# 检索返回数量 (Top-K)
RAG_TOP_K=10

# 相似度阈值 (过滤低于此值的结果)
RAG_SIMILARITY_THRESHOLD=0.4

# 文档分块大小 (字符数)
RAG_CHUNK_SIZE=512

# 分块重叠大小 (字符数)
RAG_CHUNK_OVERLAP=50

# =============================================================================
# 服务端口配置
# =============================================================================
# LlamaFactory API 端口
LLM_PORT=8000

# FastAPI 后端端口
API_PORT=8080

# Next.js 前端端口
FRONTEND_PORT=3000

# =============================================================================
# GPU 配置
# =============================================================================
# 可见 GPU 设备 (逗号分隔)
CUDA_VISIBLE_DEVICES=0,1

# =============================================================================
# 日志配置
# =============================================================================
# 日志级别 (DEBUG / INFO / WARNING / ERROR)
LOG_LEVEL=INFO

# =============================================================================
# HuggingFace 配置 (可选)
# =============================================================================
# HuggingFace 镜像站 (国内加速)
# HF_ENDPOINT=https://hf-mirror.com

# HuggingFace Token (私有模型需要)
# HF_TOKEN=your_token_here
